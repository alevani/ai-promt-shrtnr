use std::cmp::Reverse;

use linked_hash_map::LinkedHashMap;

// This program is generated by ChatGPT too
// developers shoot themselves in the foot, now ChatGPT
// shoot itself in the foot
fn generate_dictionary(sentences: &Vec<String>) -> LinkedHashMap<String, String> {
    let mut word_counts: LinkedHashMap<String, usize> = LinkedHashMap::new();

    // Count the number of occurrences of each word in the sentences
    for sentence in sentences {
        for word in sentence.split_whitespace() {
            *word_counts.entry(word.to_lowercase()).or_default() += 1;
        }
    }

    // Sort the words by frequency
    let mut words: Vec<_> = word_counts.keys().cloned().collect();
    words.sort_by_key(|word| Reverse(word_counts[word]));

    // Assign each word a token
    let mut dictionary = LinkedHashMap::new();

    words.into_iter().enumerate().for_each(|(k, v)| {
        dictionary.insert(v, excel_style(k as i32));
    });

    dictionary
}

fn translate_sentence(sentence: &str, dictionary: &LinkedHashMap<String, String>) -> String {
    sentence
        .split_whitespace()
        .map(|word| {
            dictionary
                .get(word.to_lowercase().as_str())
                .unwrap_or(&word.to_string())
                .to_string()
        })
        .collect::<Vec<_>>()
        .join(" ")
}

const LETTERS: &str = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";

fn excel_style(col: i32) -> String {
    let mut result = String::new();
    let mut col = col;
    while col > 0 {
        col -= 1;
        let (col_quotient, rem) = (col / 26, col % 26);
        col = col_quotient;
        result.insert(0, LETTERS.chars().nth(rem as usize).unwrap());
    }
    result
}

use std::fs::File;
use std::io::{self, BufRead};
use std::path::Path;

// The output is wrapped in a Result to allow matching on errors
// Returns an Iterator to the Reader of the lines of the file.
fn read_lines<P>(filename: P) -> io::Result<io::Lines<io::BufReader<File>>>
where
    P: AsRef<Path>,
{
    let file = File::open(filename)?;
    Ok(io::BufReader::new(file).lines())
}

fn main() {
    let mut train_set: Vec<String> = Vec::new();

    // File hosts must exist in current path before this produces output
    if let Ok(lines) = read_lines("./train_set.txt") {
        // Consumes the iterator, returns an (Optional) String
        for line in lines {
            if let Ok(ip) = line {
                train_set.push(ip)
            }
        }
    }

    let dictionary = generate_dictionary(&train_set);

    println!("
    I will now talk only with a token generated sentence based on the following dictionnary:

    {dictionary:?}

    Every time I write a new prompt, use the dictionary to translate the token based sentence into a prompt that you can understand. Then act as if it was the original prompt and execute what the prompt says.
        ");

    for sentence in train_set {
        println!(
            "{} => {}",
            sentence,
            translate_sentence(&sentence, &dictionary)
        );
    }
}
