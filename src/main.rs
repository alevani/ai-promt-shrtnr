use std::cmp::Reverse;

use linked_hash_map::LinkedHashMap;
pub mod input;

// This program is generated by ChatGPT too
// developers shoot themselves in the foot, now ChatGPT
// shoot itself in the foot
fn generate_dictionary(sentences: &[&str]) -> LinkedHashMap<String, String> {
    let mut word_counts: LinkedHashMap<String, usize> = LinkedHashMap::new();

    // Count the number of occurrences of each word in the sentences
    for sentence in sentences {
        for word in sentence.split_whitespace() {
            *word_counts.entry(word.to_lowercase()).or_default() += 1;
        }
    }

    // Sort the words by frequency
    let mut words: Vec<_> = word_counts.keys().cloned().collect();
    words.sort_by_key(|word| Reverse(word_counts[word]));

    // Assign each word a token
    let mut dictionary = LinkedHashMap::new();
    
    words.into_iter().enumerate().for_each(|(k, v)| {
        dictionary.insert(v, excel_style(k as i32));
    });
   
    dictionary
}

fn translate_sentence(sentence: &str, dictionary: &LinkedHashMap<String, String>) -> String {
    sentence
        .split_whitespace()
        .map(|word| {
            dictionary
                .get(word.to_lowercase().as_str())
                .unwrap_or(&word.to_string())
                .to_string()
        })
        .collect::<Vec<_>>()
        .join(" ")
}

fn generate_dictionary_from_file() -> LinkedHashMap<String, String> {
    let mut word_counts: LinkedHashMap<String, usize> = LinkedHashMap::new();

    input::get_input().split('\n').for_each(|row| {
        let mut splitted = row.split(',');
        let word = splitted.next().unwrap();
        let freq = splitted.next().unwrap();

        word_counts.insert(
            word.to_string(),
            freq.parse::<i32>().unwrap_or_default() as usize,
        );
    });

    // Sort the words by frequency
    let mut words: Vec<_> = word_counts.keys().cloned().collect();
    words.sort_by_key(|word| Reverse(word_counts[word]));

    // Assign each word a token
    let mut dictionary = LinkedHashMap::new();
    
    words.into_iter().enumerate().for_each(|(k, v)| {
        dictionary.insert(v, excel_style(k as i32));
    });
   
    dictionary
}

const LETTERS: &str = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";

fn excel_style(col: i32) -> String {
    let mut result = String::new();
    let mut col = col;
    while col > 0 {
        col -= 1;
        let (col_quotient, rem) = (col / 26, col % 26);
        col = col_quotient;
        result.insert(0, LETTERS.chars().nth(rem as usize).unwrap());
    }
    result
}

fn main() {
    // let sentences = vec!["Generate a program that prints The quick brown fox jumps over the lazy dog in rust", "Generate a program that prints Hello World in rust", "Write a rust program that outputs 'The quick brown fox jumps over the lazy dog'", "Create a rust code that displays 'The quick brown fox jumps over the lazy dog'", "Build a rust program that prints 'The quick brown fox jumps over the lazy dog'", "Compose a rust script that prints the sentence 'The quick brown fox jumps over the lazy dog'", "Design a rust program that says 'The quick brown fox jumps over the lazy dog' on the console", "Make a rust code that shows 'The quick brown fox jumps over the lazy dog' on the screen", "Develop a rust program that prints 'The quick brown fox jumps over the lazy dog' on the output"];
    let sentences = vec!["Write a prompt that generates Rust code to output hello world"];
    // let dictionary = generate_dictionary(&sentences);
    let dictionary = generate_dictionary_from_file();

    //     println!("
    // I will now talk only with a token generated sentence based on the following dictionnary:

    // {dictionary:?}

    // Every time I write a new prompt, use the dictionary to translate the token based sentence into a prompt that you can understand. Then act as if it was the original prompt and execute what the prompt says.
    //     ");

    for sentence in sentences {
        println!(
            "{} => {}",
            sentence,
            translate_sentence(sentence, &dictionary)
        );
    }
}
